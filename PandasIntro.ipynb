{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python: Introduction to Data Analysis with Pandas\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to this tutorial about doing data analysis with `pandas`. If you did the Introductory Python tutorial, you'll rememember we briefly looked at the `pandas` package as a way of quickly loading a .csv file to extract some data. This tutorial looks at pandas in some more depth. \n",
    "\n",
    "## What is pandas?\n",
    "\n",
    "Pandas is a package commonly used to deal with data analysis. It simplifies the loading of data from external sources such as text files and databases, as well as providing ways of analysing and manipulating data once it is loaded into your computer. The features provided in pandas automate and simplify a lot of the commonly used tasks that would take many lines of code to write in the basic Python langauge.\n",
    "\n",
    "_If you have used R's dataframes before, or the NumPy package in Python, you may find some similarities in the Python `pandas` package. But if not, don't worry because this tutorial doesn't assume any knowledge of NumPy or R, only basic-level Python._\n",
    "\n",
    "Pandas is a hugely popular, and still growing, Python library used across a range of disciplines from environmental and climate science, through to social science, linguistics, biology, as well as a number of applications in industry such as data analytics, financial trading and many others. If you came to the last tutorial, you'll know I'm a fan of these StackOverflow graphs showing usage of programming languages over time. Well, I found another one showing the growth of Pandas compared to some other Python software libraries:\n",
    "\n",
    "(image here)\n",
    "\n",
    "Pandas is best suited for structured, __labled__ data, in other words, tabular data, that has headings or names associated with each column of data. The pandas.org website describes its data-handling strengths as:\n",
    "\n",
    " - Tabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet\n",
    " - Ordered and unordered (not necessarily fixed-frequency) time series data.\n",
    " - Arbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels\n",
    " - Any other form of observational / statistical data sets. The data actually need not be labeled at all to be placed into a pandas data structure\n",
    " \n",
    "Some other important points to note about pandas are:\n",
    "\n",
    " - pandas is __fast__. Python sometimes gets a bad rap for being a bit slow compared to 'compiled' languages such as C and Fortran. But deep down in the internals of Pandas, it is actually written in C, and so processing large datasets is no problem for pandas.\n",
    " - pandas is a dependency of another library called `statsmodels`, making it an important part of the statistical computing ecosystem in Python.\n",
    " \n",
    "## What will be covered in this tutorial\n",
    "\n",
    " - Aims. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conventions for using pandas\n",
    "All the examples in this tutorial assume you have installed the Python library pandas, either through using a scientific python distribution such as Anaconda/Spyder, or by installing it using a package-manager. If you are writing scripts, it's assumed that you have the import statement at the top of your script like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time we use a pandas feature thereafter, we can shorten what we type by just typing `pd`, such as `pd.some_function()`. Try the following to see which version of pandas you are running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas data structures\n",
    "Pandas has two core datastructures used to store data: The _Series_ and the _Dataframe_. \n",
    "\n",
    "### Series\n",
    "\n",
    "The series is a one-dimensional array-like structure designed to hold a single array (or 'column') of data and an associated array called of data labels, called an _index_. We can create a series to experiment with just by passing a list of data, let's use numbers in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.6\n",
       "1    2.1\n",
       "2   -4.0\n",
       "3    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series = pd.Series([4.6, 2.1, -4.0, 3.0])\n",
    "my_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that printing out our _Series_ object prints out the values and the index numbers. If we just wanted the values, we can do this with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.6,  2.1, -4. ,  3. ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a lot of applications, a plain old Series is probably not a lot of use, but it is the core component of the pandas workhorse, the _DataFrame_, so it's useful to know about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames\n",
    "The DataFrame represents tabular data, a bit like a spreadsheet. DataFrames are organised into colums (each of which is a _Series_), and each column can store a single data-type, such as floating point numbers, strings, boolean values etc. DataFrames can be indexed by either their row or column names. (They are similar in many ways to R's `data.frame`.)\n",
    "\n",
    "We can create a dataframe in pandas from a python dictionary, or by loading in a text file containing tabular data.\n",
    "\n",
    "#### A note on dictionaries\n",
    "\n",
    "_You can skip this section if you already know about the built-in Python data structure called a `dictionary`_\n",
    "\n",
    "Dictionaries are a Python data structure that contain a set of key:value pairs. If you think of a written language dictionary, say for English-Hungarian, and you wanted to know the Hungarian word for \"spaceship\", you would look-up the English word (the `key`) and the dictionary would give you the Hungarian translation (the `value`). So the \"key-value pair\" would be `'spaceship': 'űrhajó'`. \n",
    "\n",
    "To construct this in Python, we would write:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hungarian_dictionary = {'spaceship': 'űrhajó'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could then look-up items in our dictionary with this syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'űrhajó'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hungarian_dictionary['spaceship']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries can have multiple entries (multiple key-value pairs), and these are separated with a comma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hungarian_dictionary = {'spaceship': 'űrhajó',\n",
    "                        'watermelon': 'görögdinnye',\n",
    "                        'bicycle': 'kerékpár'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `values` in dictionaries are not limtied to single strings or words. Values can be any Python object such as numbers, lists, tuples, or even other dictionaries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Names (keys) mapped to a tuple (the value) containing the height, lat and longitude.\n",
    "scottish_hills = {'Ben Nevis': (1345, 56.79685, -5.003508),\n",
    "                  'Ben Macdui': (1309, 57.070453, -3.668262),\n",
    "                  'Braeriach': (1296, 57.078628, -3.728024),\n",
    "                  'Cairn Toul': (1291, 57.054611, -3.71042),\n",
    "                  'Sgòr an Lochain Uaine': (1258, 57.057999, -3.725416)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking up a Scottish mountain using its name as the `key` would then give us the height, latitude and longitude as the `value` returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1296, 57.078628, -3.728024)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scottish_hills['Braeriach']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to DataFrames...\n",
    "If we didn't have any real data to play with from an external file, we could manually create a DataFrame from a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ben Macdui    Ben Nevis    Braeriach   Cairn Toul  Sgòr an Lochain Uaine\n",
      "0  1309.000000  1345.000000  1296.000000  1291.000000            1258.000000\n",
      "1    57.070453    56.796850    57.078628    57.054611              57.057999\n",
      "2    -3.668262    -5.003508    -3.728024    -3.710420              -3.725416\n"
     ]
    }
   ],
   "source": [
    "hills = pd.DataFrame(scottish_hills)\n",
    "print(hills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this is not necessarily the most logical order to store data. It would probably make more sense for the columns to be categories or types of data, rather than names. To do this, we need to think about how to structure our dictionary. Pandas works best with dictionaries when the dictionary keys refer to column names or headers. Here's a better dictionary to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Height              Hill Name   Latitude  Longitude\n",
      "0    1345              Ben Nevis  56.796850  -5.003508\n",
      "1    1309             Ben Macdui  57.070453  -3.668262\n",
      "2    1296              Braeriach  57.078628  -3.728024\n",
      "3    1291             Cairn Toul  57.054611  -3.710420\n",
      "4    1258  Sgòr an Lochain Uaine  57.057999  -3.725416\n"
     ]
    }
   ],
   "source": [
    "scottish_peaks = {'Hill Name': ['Ben Nevis', 'Ben Macdui', 'Braeriach', 'Cairn Toul', 'Sgòr an Lochain Uaine'],\n",
    "                  'Height': [1345, 1309, 1296, 1291, 1258],\n",
    "                  'Latitude': [56.79685, 57.070453, 57.078628, 57.054611, 57.057999],\n",
    "                  'Longitude': [-5.003508, -3.668262, -3.728024, -3.71042, -3.725416]}\n",
    "\n",
    "dataframe = pd.DataFrame(scottish_peaks)\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are ordered alphabetically by default, but we can specify the order using the `columns` keyword. (Another way would be to use an `OrderedDict` data structure, but that's not covered in this tutorial...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Hill Name  Height   Latitude  Longitude\n",
      "0              Ben Nevis    1345  56.796850  -5.003508\n",
      "1             Ben Macdui    1309  57.070453  -3.668262\n",
      "2              Braeriach    1296  57.078628  -3.728024\n",
      "3             Cairn Toul    1291  57.054611  -3.710420\n",
      "4  Sgòr an Lochain Uaine    1258  57.057999  -3.725416\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(scottish_peaks, columns=['Hill Name', 'Height', 'Latitude', 'Longitude'])\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the dictionary keys have become column headers running along the top, and as with the Series, an index number has been automatically generated.\n",
    "\n",
    "Pandas dataframes have many useful methods that can be used to inspect the data and manipulate it. We are going to have a look at just a few of them.\n",
    "\n",
    "If our DataFrame was huge, we would not want to print all of it to screen, instead we could have a look at the first few items with the `head` method, which takes the number of rows you want to view as its argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Hill Name  Height   Latitude  Longitude\n",
      "0   Ben Nevis    1345  56.796850  -5.003508\n",
      "1  Ben Macdui    1309  57.070453  -3.668262\n",
      "2   Braeriach    1296  57.078628  -3.728024\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also look at the last couple of values with the `tail` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Hill Name  Height   Latitude  Longitude\n",
      "3             Cairn Toul    1291  57.054611  -3.710420\n",
      "4  Sgòr an Lochain Uaine    1258  57.057999  -3.725416\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing data\n",
    "\n",
    "Our columns are individual Series of data. We can access them by referring to the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                Ben Nevis\n",
      "1               Ben Macdui\n",
      "2                Braeriach\n",
      "3               Cairn Toul\n",
      "4    Sgòr an Lochain Uaine\n",
      "Name: Hill Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframe['Hill Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1345\n",
       "1    1309\n",
       "2    1296\n",
       "3    1291\n",
       "4    1258\n",
       "Name: Height, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['Height']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pandas DataFrames are accessed primarily by columns, in a sense the row is less important to a DataFrame. For example, try the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouch! That's a lot of error message... __The columns cannot be accessed by their index number in this way__, you must use the column name. You may have thought that this might return the row index instead, but we have to use a different method to get the row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hill Name    Ben Nevis\n",
       "Height            1345\n",
       "Latitude       56.7968\n",
       "Longitude     -5.00351\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iloc` method gives us access to the DataFrame in more traditional 'matrix' style notation, i.e. `[row, column]` notation. So if we wanted to get the height of Ben Nevis specifically, we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ben Nevis'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to remeber this is that `iloc` is short for \"**i**nteger **loc**ation\". But a more pandas-style approach would be to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ben Nevis'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['Hill Name'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, we are saying to our pandas DataFrame _get me the `Height` Series, and give me the zero-th item in that Series._ Remember Python uses zero-indexing (starts counting items from zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even quicker way to access our columns (less typing) is to treat the names as if they were attributes of our DataFrame, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1345\n",
       "1    1309\n",
       "2    1296\n",
       "3    1291\n",
       "4    1258\n",
       "Name: Height, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.Height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering data\n",
    "\n",
    "We can also apply conditions to the data we are inspecting, such as to filter our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: Height, dtype: bool"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.Height > 1300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a new Series of True/False values though. To actually filter the data, we need to use this Series to mask our original DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[dataframe.Height > 1300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending data\n",
    "\n",
    "We can also append data to the DataFrame. This is done using the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Hill Name  Height   Latitude  Longitude     Region\n",
      "0              Ben Nevis    1345  56.796850  -5.003508   Grampian\n",
      "1             Ben Macdui    1309  57.070453  -3.668262  Cairngorm\n",
      "2              Braeriach    1296  57.078628  -3.728024  Cairngorm\n",
      "3             Cairn Toul    1291  57.054611  -3.710420  Cairngorm\n",
      "4  Sgòr an Lochain Uaine    1258  57.057999  -3.725416  Cairngorm\n"
     ]
    }
   ],
   "source": [
    "dataframe['Region'] = ['Grampian', 'Cairngorm', 'Cairngorm', 'Cairngorm', 'Cairngorm']\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from a file\n",
    "\n",
    "Pandas has built in tools for reading data from a variety of data formats, including Excel spreadsheets, raw text and csv files. It can also interface with databases such as MySQL, but we are not going to cover databases in this tutorial.\n",
    "\n",
    "We've provided the `scottish_peaks.csv` file, which contains **all** the mountains above 3000 feet (about 914 metres) in Scotland. We can load this easily into a DataFrame with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"data/scottish_peaks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Hill Name  Height   Latitude  Longitude    Osgrid\n",
      "0       A' Bhuidheanach Bheag   936.0  56.870342  -4.199001  NN660775\n",
      "1               A' Chailleach   997.0  57.693800  -5.128715  NH136714\n",
      "2               A' Chailleach   929.2  57.109564  -4.179285  NH681041\n",
      "3  A' Chraileag (A' Chralaig)  1120.0  57.184186  -5.154837  NH094147\n",
      "4             A' Ghlas-bheinn   918.0  57.255090  -5.303687  NH008231\n",
      "5               A' Mhaighdean   967.0  57.719644  -5.346720  NH007749\n",
      "6              A' Mharconaich   973.2  56.857002  -4.290668  NN604762\n",
      "7                  Am Basteir   934.0  57.247931  -6.202982  NG465253\n",
      "8                   Am Bodach  1031.8  56.741727  -4.983393  NN176650\n",
      "9               Am Faochagach   953.0  57.771801  -4.853899  NH303793\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this table contains the hills in alphabetical order. We can sort the DataFrame using the `sort_values` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Hill Name  Height   Latitude  Longitude    Osgrid\n",
      "92                     Ben Nevis  1344.5  56.796891  -5.003675  NN166712\n",
      "88   Ben Macdui (Beinn Macduibh)  1309.0  57.070368  -3.669099  NN988989\n",
      "104                    Braeriach  1296.0  57.078298  -3.728389  NN953999\n",
      "115                   Cairn Toul  1291.0  57.054397  -3.710773  NN963972\n",
      "212        Sgor an Lochain Uaine  1258.0  57.058369  -3.725797  NN954976\n"
     ]
    }
   ],
   "source": [
    "sorted_hills = dataframe.sort_values(by=['Height'], ascending=False)\n",
    "\n",
    "# Let's have a look at the top 5 to check\n",
    "print(sorted_hills.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(dataframe['Height'], dataframe['Latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataframe['Longitude'], dataframe['Latitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Plotting data onto maps with Cartopy\n",
    "\n",
    "Note: You need to have the cartopy module installed for this next part of the tutorial to work. The easiest way to do this on your own computer is with the package manager conda:\n",
    "\n",
    "`conda install -c conda-forge cartopy`\n",
    "\n",
    "This is only a short example, so don't worry if you can't install it right now, just try to follow the code and have  look at the final figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "ax = plt.axes(projection=ccrs.Mercator())\n",
    "ax.coastlines('10m')\n",
    "\n",
    "ax.xaxis.set_visible(True)\n",
    "ax.yaxis.set_visible(True)\n",
    "\n",
    "ax.set_yticks([56,57,58,59], crs=ccrs.PlateCarree())\n",
    "ax.set_xticks([-8, -6, -4, -2], crs=ccrs.PlateCarree())\n",
    "\n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter)\n",
    "\n",
    "ax.set_extent([-8, -1.5, 55.3, 59])\n",
    "\n",
    "plt.scatter(dataframe['Longitude'],dataframe['Latitude'],\n",
    "                    color='red', marker='^', transform=ccrs.PlateCarree())\n",
    "plt.savefig(\"munros.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Hill Name  Height   Latitude  Longitude     Region\n",
      "0              Ben Nevis    1345  56.796850  -5.003508   Grampian\n",
      "1             Ben Macdui    1309  57.070453  -3.668262  Cairngorm\n",
      "2              Braeriach    1296  57.078628  -3.728024  Cairngorm\n",
      "3             Cairn Toul    1291  57.054611  -3.710420  Cairngorm\n",
      "4  Sgòr an Lochain Uaine    1258  57.057999  -3.725416  Cairngorm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scottish_hills = {'Hill Name': ['Ben Nevis', 'Ben Macdui', 'Braeriach', 'Cairn Toul', 'Sgòr an Lochain Uaine'],\n",
    "                  'Height': [1345, 1309, 1296, 1291, 1258],\n",
    "                  'Latitude': [56.79685, 57.070453, 57.078628, 57.054611, 57.057999],\n",
    "                  'Longitude': [-5.003508, -3.668262, -3.728024, -3.71042, -3.725416]}\n",
    "\n",
    "dataframe = pd.DataFrame(scottish_hills, columns=['Hill Name', 'Height', 'Latitude', 'Longitude'])\n",
    "dataframe['Region'] = ['Grampian', 'Cairngorm', 'Cairngorm', 'Cairngorm', 'Cairngorm']\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
